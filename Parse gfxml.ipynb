{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea037e80",
   "metadata": {},
   "source": [
    "## Read GaiaFormsXML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ecab75e-50ce-4303-88f4-b996783c3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import xmltodict as xtd\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2119ae9",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf6eafc5",
   "metadata": {},
   "source": [
    "## Parse gfxml file and get general info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11f0eeb2-7083-43ae-809f-87dc9f2b32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gfxml(gfxml_path):\n",
    "\n",
    "    # parses gfxml and returns it as a dictionary\n",
    "\n",
    "    with open(gfxml_path, encoding='utf-8') as gfxml:\n",
    "        gfdict = xtd.parse(gfxml.read())\n",
    "    \n",
    "    return gfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90eefafc-1f2a-4d05-9ed2-94c5e7ffa436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_id(gfdict):\n",
    "\n",
    "    # pass dictionary from parsed gfxml and return location ID\n",
    "    \n",
    "    location_id = gfdict['MarineSampleDescription']['Location']\n",
    "    \n",
    "    return location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e71e6674-9196-4a7b-97f2-d4ef9ad4c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_list(gfdict):\n",
    "\n",
    "    # pass dictionary from parsed gfxml and return list of samples from that location\n",
    "\n",
    "    sample_list = gfdict['MarineSampleDescription']['Pages']['MarineSampleDescriptionPage']\n",
    "    \n",
    "    # while parsing, if there are multiple samples they are returned as a list of dictionaries\n",
    "    # but when it is only one sample, the dictionary is not contained in a list\n",
    "    # to enable further processing analogous to list of samples, wrap it in a list\n",
    "    if isinstance(sample_list, dict):\n",
    "        sample_list = [sample_list]\n",
    "\n",
    "    return sample_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4de411e2",
   "metadata": {},
   "source": [
    "## Get HCl tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de0b9359-6fbe-4115-9d64-d1ce612822d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will later when iterating over sample list to get called each time to get all HCl tests in that sample\n",
    "\n",
    "def get_tests(sample):\n",
    "\n",
    "    # Sample ID\n",
    "    sample_id = sample['SampleNo']\n",
    "\n",
    "    # Sample depth\n",
    "    # sometimes contains weird \"nil\" string which can not be converted to float\n",
    "    # if that happens, catch exception and set sample depth = None\n",
    "    try:\n",
    "        sample_depth_m = float(sample['Depth'])\n",
    "    except:\n",
    "        sample_depth_m = None\n",
    "    \n",
    "    # save HCl test information to variable\n",
    "    # if empty, tests = None\n",
    "    try:\n",
    "        tests = sample['HClTests']['MarineHClTest']\n",
    "    except:\n",
    "        tests = None\n",
    "    # to preserve empty rows (samples without HCl tests) (optional):\n",
    "    #     tests = [{'TestId': None, 'SubSampleRef': None, 'TestOffset': None, 'Reaction': None, 'Residue': None}]\n",
    "    \n",
    "    # return sample information (ID, depth, HCl tests) as dictionary\n",
    "    sample_info = {\n",
    "                    'Sample ID' : sample_id,\n",
    "                    'Depth' : sample_depth_m,\n",
    "                    'Tests' : tests\n",
    "                  }\n",
    "\n",
    "    return sample_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57d6e97b-e300-452b-9365-418fe0dc36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tests_dataframe(location_id, sample_info):\n",
    "    \n",
    "    # create dataframe from tests in sample info dictionary\n",
    "\n",
    "    # if tests are empty, return no rows\n",
    "    if sample_info['Tests'] == None:\n",
    "        return None\n",
    "    else:\n",
    "        # hacky but works:\n",
    "        # if multiple tests, they are wrapped in a list. but if it's a single test, it's just a dictionary and needs to be passed an index\n",
    "        if isinstance(sample_info['Tests'], list):\n",
    "            df = pd.DataFrame(sample_info['Tests'])\n",
    "        else:\n",
    "            df = pd.DataFrame(sample_info['Tests'], index=[0])\n",
    "\n",
    "        # add location, sample id\n",
    "        df['Location'] = location_id\n",
    "        df['Sample ID'] = sample_info['Sample ID']\n",
    "\n",
    "        # calculate test depth: sample depth + offset\n",
    "        df = df.astype({'TestOffset' : float})\n",
    "        df['Depth'] = sample_info['Depth'] + df['TestOffset'] / 100\n",
    "        \n",
    "        # drop unused columns and reorder\n",
    "        df.drop(['TestId', 'TestOffset', 'SubSampleRef'], axis=1, inplace=True)\n",
    "        df = df[['Location', 'Sample ID', 'Depth', 'Reaction', 'Residue']]\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99189bea-dd69-436b-854b-2c941d5752c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_data_from_gfxml(gfxml_path):\n",
    "\n",
    "    # use custom functions defined above to pass only the gfxml file path and return the final HCl test dataframe\n",
    "    \n",
    "    # parse gfxml\n",
    "    gfdict = parse_gfxml(gfxml_path)\n",
    "    # get location id\n",
    "    location_id = get_location_id(gfdict)\n",
    "    # get sample list\n",
    "    sample_list = get_sample_list(gfdict)\n",
    "\n",
    "    # instantiate empty dataframe to contain all samples\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # iterate over sample list\n",
    "    for sample in sample_list:\n",
    "        # get test info dataframe for every sample\n",
    "        sample_info = get_tests(sample)\n",
    "        sample_df = create_tests_dataframe(location_id, sample_info)\n",
    "        # add sample test info to empty dataframe\n",
    "        df = pd.concat([df, sample_df])\n",
    "    \n",
    "    # return dataframe with all samples and HCl tests\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "814e9677",
   "metadata": {},
   "source": [
    "## Get layer descriptions and filter for contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f7dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will later when iterating over sample list to get called each time to get all layers described in that sample\n",
    "\n",
    "def get_layers(sample):\n",
    "\n",
    "    # Sample ID\n",
    "    sample_id = sample['SampleNo']\n",
    "\n",
    "    # Sample depth\n",
    "    # sometimes contains weird \"nil\" string which can not be converted to float\n",
    "    # if that happens, sample depth = None\n",
    "    try:\n",
    "        sample_depth_m = float(sample['Depth'])\n",
    "    except:\n",
    "        sample_depth_m = None\n",
    "    \n",
    "    # save layer information to variable\n",
    "    # if empty, tests = None\n",
    "    try:\n",
    "        layers = sample['Layers']\n",
    "    except:\n",
    "        layers = None\n",
    "    # to preserve empty rows (samples without layers):\n",
    "    #     tests = [{'TestId': None, 'SubSampleRef': None, 'TestOffset': None, 'Reaction': None, 'Residue': None}]\n",
    "    \n",
    "    sample_info = {\n",
    "                    'Sample ID' : sample_id,\n",
    "                    'Depth' : sample_depth_m,\n",
    "                    'Layers' : layers\n",
    "                  }\n",
    "\n",
    "    return sample_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eea0fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer_dataframe(location_id, layer_info):\n",
    "\n",
    "    # create dataframe from layers in sample dictionary\n",
    "\n",
    "    # if layers are empty, return no rows\n",
    "    if layer_info['Layers'] == None:\n",
    "        return None\n",
    "    else:\n",
    "        # create dataframe from layer dictionary\n",
    "        layers = layer_info['Layers']['StandardLayer']\n",
    "        df = pd.DataFrame(layers)\n",
    "\n",
    "        # check if there is a layer description, otherwise return None\n",
    "        if 'Description' not in df.columns:\n",
    "            return None\n",
    "        else:\n",
    "            # add location, sample id\n",
    "            df['Location'] = location_id\n",
    "            df['Sample ID'] = layer_info['Sample ID']\n",
    "            # calculate DepthFrom and DepthTo of layer from depth + boundaries\n",
    "            df = df.astype({'UpperBoundary' : float, 'LowerBoundary' : float})\n",
    "            df['DepthFrom'] = layer_info['Depth'] + df['UpperBoundary'] / 100\n",
    "            df['DepthTo'] = layer_info['Depth'] + df['LowerBoundary'] / 100\n",
    "\n",
    "            # drop unused columns and reorder\n",
    "            df.drop(['@xsi:type', 'Properties', 'IdentificationStandard', 'Id', 'UpperBoundary', 'LowerBoundary'], axis=1, inplace=True)\n",
    "            df = df[['Location', 'Sample ID', 'DepthFrom', 'DepthTo', 'Description']]\n",
    "\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33d439cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to filter for keywords (carbonate content, marl)\n",
    "\n",
    "def filter_carb_content(df):\n",
    "\n",
    "    # check if there is a layer description, otherwise return None\n",
    "    if 'Description' not in df.columns:\n",
    "        return df\n",
    "    else:\n",
    "        condition = df['Description'].str.lower().str.contains('calc') | df['Description'].str.lower().str.contains('carbonate')\n",
    "        filtered_df = df[condition]\n",
    "\n",
    "        return filtered_df\n",
    "\n",
    "def filter_marl(df):\n",
    "\n",
    "    # check if there is a layer description, otherwise return None\n",
    "    if 'Description' not in df.columns:\n",
    "        return df\n",
    "    else:\n",
    "        condition = df['Description'].str.lower().str.contains('marl')\n",
    "        filtered_df = df[condition]\n",
    "\n",
    "        return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e0cf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_from_gfxml(gfxml_path, filter):\n",
    "\n",
    "    # use custom functions defined above to pass only the gfxml file path and return the final samples and layers dataframe\n",
    "\n",
    "    # parse gfxml\n",
    "    gfdict = parse_gfxml(gfxml_path)\n",
    "    # get location id\n",
    "    location_id = get_location_id(gfdict)\n",
    "    # get sample list\n",
    "    sample_list = get_sample_list(gfdict)\n",
    "\n",
    "    # instantiate empty dataframe to contain all samples\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # iterate over sample list\n",
    "    for sample in sample_list:\n",
    "        # get test info dataframe for every sample\n",
    "        layer_info = get_layers(sample)\n",
    "        layer_df = create_layer_dataframe(location_id, layer_info)\n",
    "        # add sample test info to empty dataframe\n",
    "        df = pd.concat([df, layer_df])\n",
    "\n",
    "    # filter dataframe for keyword passed to this function\n",
    "    if filter == 'carb':\n",
    "        df = filter_carb_content(df)\n",
    "    if filter == 'marl':\n",
    "        df = filter_marl(df)\n",
    "\n",
    "    # reset index and return dataframe with filtered samples and layers\n",
    "    df = df.reset_index().drop('index', axis=1)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fcc7cd2",
   "metadata": {},
   "source": [
    "# Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fcde87d-90d3-4e71-b791-fb7648573c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to export dataframes to excel files\n",
    "\n",
    "def save_excel_if_not_empty(df, path):\n",
    "\n",
    "    # use global variable excels to track files and tables created\n",
    "    global excels\n",
    "    \n",
    "    # if df is not empty, export and update tracker\n",
    "    if len(df) > 0:\n",
    "        df.to_excel(path, index=False)\n",
    "        excels['Files checked'] += 1\n",
    "        excels['Excels created'] += 1\n",
    "\n",
    "    # if empty, update tracker and no file export\n",
    "    else:\n",
    "        excels['Files checked'] += 1\n",
    "\n",
    "    return excels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b7775af",
   "metadata": {},
   "source": [
    "# Iterate over folder with gfxml files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "896341bf",
   "metadata": {},
   "source": [
    "## HCl test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "203a8e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Files checked': 495, 'Excels created': 33}\n"
     ]
    }
   ],
   "source": [
    "# set directory with gfxml files\n",
    "directory = r'C:\\Users\\user\\example_path\\gfxml'\n",
    "\n",
    "# create list of gfxml files in directory\n",
    "file_list = [file for file in os.listdir(directory) if file.endswith('.gfxml')]\n",
    "\n",
    "# set file for excel exports\n",
    "excel_path = r'CC:\\Users\\user\\example_path\\excels\\hcl'\n",
    "\n",
    "# set tracker to 0\n",
    "excels = {'Files checked' : 0, 'Excels created' : 0}\n",
    "\n",
    "# iterate over all files\n",
    "for file in file_list:\n",
    "    \n",
    "    # filename = location name + xlsx\n",
    "    filename = file.split('_MSD')[0] + '.xlsx'\n",
    "\n",
    "    file_directory = os.path.join(directory, file)\n",
    "    \n",
    "    # call function with all single custom functions \n",
    "    df = test_data_from_gfxml(file_directory)\n",
    "    \n",
    "    # set path for excel files\n",
    "    save_path = os.path.join(excel_path, filename)\n",
    "    \n",
    "    # call excel export function\n",
    "    stats = save_excel_if_not_empty(df, save_path)\n",
    "\n",
    "# print statistics\n",
    "print(stats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "861b3c81",
   "metadata": {},
   "source": [
    "## Layer descriptions with filters applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30483069-9bf0-4d3a-a1eb-0ef4469f01d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Files checked': 495, 'Excels created': 311}\n"
     ]
    }
   ],
   "source": [
    "# works analogous to cell above (HCl data)\n",
    "\n",
    "directory = r'C:\\Users\\user\\example_path\\gfxml'\n",
    "\n",
    "file_list = [file for file in os.listdir(directory) if file.endswith('.gfxml')]\n",
    "\n",
    "excel_path = r'C:\\Users\\user\\example_path\\excels\\carb'\n",
    "\n",
    "excels = {'Files checked' : 0, 'Excels created' : 0}\n",
    "\n",
    "# sometimes there are multiple gfxml files for one location\n",
    "# to combine samples in one excel file:\n",
    "# save last dataframe and compare next one to it and combine if they are the same location\n",
    "\n",
    "# first set last_df to an empty df\n",
    "last_df = pd.DataFrame({'Location' : ''}, index=[0])\n",
    "\n",
    "for file in file_list:\n",
    "    \n",
    "    filename = file.split('_MSD')[0] + '.xlsx'\n",
    "    \n",
    "    file_directory = os.path.join(directory, file)\n",
    "    \n",
    "    df = data_from_gfxml(file_directory, filter='carb')\n",
    "\n",
    "    # if df is not empty, compare to last dataframe\n",
    "    if len(df) > 0:\n",
    "        if df.iloc[0, 0] == last_df.iloc[0, 0]:\n",
    "            # append current sample to last_df if they are the same location\n",
    "            df = pd.concat([last_df, df])\n",
    "\n",
    "    # set current df to last_df to enable comparison for the next one\n",
    "        last_df = df\n",
    "    \n",
    "    save_path = os.path.join(excel_path, filename)\n",
    "    \n",
    "    stats = save_excel_if_not_empty(df, save_path)\n",
    "\n",
    "\n",
    "print(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c724d3af6c6d51fb9314739016616a342fb85ea12969c9120cddf7a9b2e1e06c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
